{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import reduce\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '/media/school/project/temp_2018-5-year/2018_acs/INTERMEDIATE_DATA'\n",
      "[Errno 17] File exists: '/media/school/project/temp_2018-5-year/2018_acs/RESULTS/'\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "WORK_DIR = '/media/school/project/temp_2018-5-year/2018_acs'\n",
    "RECALC_DATA = True # refreshes data from scratch when True, reads pickles when False\n",
    "#################################\n",
    "\n",
    "# Directories that exist\n",
    "SF_DIR = os.path.join(WORK_DIR, 'All_Geographies_Not_Tracts_Block_Groups')\n",
    "SF_TEMPLATE_DIR = os.path.join(WORK_DIR, '2018_5yr_Summary_FileTemplates')\n",
    "\n",
    "# Directories created by this script\n",
    "INT_DIR = os.path.join(WORK_DIR, 'INTERMEDIATE_DATA')\n",
    "RES_DIR = os.path.join(WORK_DIR, 'RESULTS/')\n",
    "\n",
    "try:\n",
    "    os.makedirs(INT_DIR)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "try:\n",
    "    os.makedirs(RES_DIR)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pkl(file_path, data):\n",
    "    with open(file_path, 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def read_pkl(file_path):\n",
    "    with open(file_path, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary files start with e, m, or g, indicating:\n",
    "\n",
    "* e: estimates\n",
    "* m: margins of error\n",
    "* g: geography files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/school/project/temp_2018-5-year/2018_acs/All_Geographies_Not_Tracts_Block_Groups\n"
     ]
    }
   ],
   "source": [
    "print(SF_DIR)\n",
    "sf_files = os.listdir(SF_DIR)\n",
    "# verify present files fall into the three categories, as denoted by first letter of filename\n",
    "for first_letter in [x[0] for x in sf_files]:\n",
    "    assert first_letter in ['e', 'm', 'g']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build 'Estimates' Data Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FILEID</td>\n",
       "      <td>FILEID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FILETYPE</td>\n",
       "      <td>FILETYPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STUSAB</td>\n",
       "      <td>STUSAB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHARITER</td>\n",
       "      <td>CHARITER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEQUENCE</td>\n",
       "      <td>SEQUENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26997</th>\n",
       "      <td>B99088_004</td>\n",
       "      <td>ALLOCATION OF TRAVEL TIME TO WORK FOR WORKPLAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26998</th>\n",
       "      <td>B99088_005</td>\n",
       "      <td>ALLOCATION OF TRAVEL TIME TO WORK FOR WORKPLAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26999</th>\n",
       "      <td>B99089_001</td>\n",
       "      <td>ALLOCATION OF VEHICLES AVAILABLE FOR WORKERS F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27000</th>\n",
       "      <td>B99089_002</td>\n",
       "      <td>ALLOCATION OF VEHICLES AVAILABLE FOR WORKERS F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27001</th>\n",
       "      <td>B99089_003</td>\n",
       "      <td>ALLOCATION OF VEHICLES AVAILABLE FOR WORKERS F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27002 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           column                                        description\n",
       "0          FILEID                                             FILEID\n",
       "1        FILETYPE                                           FILETYPE\n",
       "2          STUSAB                                             STUSAB\n",
       "3        CHARITER                                           CHARITER\n",
       "4        SEQUENCE                                           SEQUENCE\n",
       "...           ...                                                ...\n",
       "26997  B99088_004  ALLOCATION OF TRAVEL TIME TO WORK FOR WORKPLAC...\n",
       "26998  B99088_005  ALLOCATION OF TRAVEL TIME TO WORK FOR WORKPLAC...\n",
       "26999  B99089_001  ALLOCATION OF VEHICLES AVAILABLE FOR WORKERS F...\n",
       "27000  B99089_002  ALLOCATION OF VEHICLES AVAILABLE FOR WORKERS F...\n",
       "27001  B99089_003  ALLOCATION OF VEHICLES AVAILABLE FOR WORKERS F...\n",
       "\n",
       "[27002 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build data dictionary of encoded column name: description\n",
    "SF_DATA_DICT_dict = {}\n",
    "for f in os.listdir(SF_TEMPLATE_DIR):\n",
    "    if not f.startswith('seq'):\n",
    "        continue\n",
    "    file_path = os.path.join(SF_TEMPLATE_DIR, f)\n",
    "    template_data = pd.read_excel(file_path, sheet_name='e')\n",
    "    mapping = dict(zip(template_data.columns, template_data.iloc[0]))\n",
    "    SF_DATA_DICT_dict.update(mapping)\n",
    "SF_DATA_DICT = pd.Series(SF_DATA_DICT_dict).reset_index()\n",
    "SF_DATA_DICT.columns = ['column', 'description']\n",
    "SF_DATA_DICT.to_pickle(os.path.join(INT_DIR, 'SF_DATA_DICT.pkl'))\n",
    "SF_DATA_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build 'Estimates' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, prepare dict of {<int>seq: column names} for estimates to speed up lookups\n",
    "COL_NAME_LU = {}\n",
    "for template in os.listdir(SF_TEMPLATE_DIR):\n",
    "    if not template.startswith('seq'):\n",
    "        continue\n",
    "    seq = int(template.split('.')[0][3:])\n",
    "    columns = pd.read_excel(os.path.join(SF_TEMPLATE_DIR, template), sheet_name='e').columns\n",
    "    COL_NAME_LU[seq] = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if RECALC_DATA:\n",
    "#     # build dataframes by state, then later all data will be concatenated\n",
    "#     # This makes things more efficient due to the large volume of tables.\n",
    "#     RESULTS = {}\n",
    "#     sf_e_files = [x for x in sf_files if x[0]=='e']\n",
    "#     for i, f in enumerate(sf_e_files):\n",
    "#         print('\\rPercent complete: {}%'.format(round((float(i+1)/len(sf_e_files))*100., 2)), end='')\n",
    "#         # get filetype\n",
    "#         ftype = f[0]\n",
    "#         # get path to file for reading\n",
    "#         file_path = os.path.join(SF_DIR, f)\n",
    "#         # get state\n",
    "#         state = f[6:8]\n",
    "#         # get sequence\n",
    "#         seq = int(f[8:12])\n",
    "#         # look up column names for this file\n",
    "#         columns = COL_NAME_LU[seq]\n",
    "#         # read the data and set the appropriate column names\n",
    "#         data = pd.read_csv(file_path, header=None, names=columns, low_memory=False)\n",
    "#         # drop unnecessary columns\n",
    "#         data.drop(columns=['FILEID', 'FILETYPE', 'CHARITER', 'SEQUENCE'], inplace=True)\n",
    "#         # set index for concatenation - needed because `.merge()` on\n",
    "#         # this many files takes FOREVER.\n",
    "#         data.set_index(['STUSAB','LOGRECNO'], inplace=True)\n",
    "\n",
    "#         # merge data for current state\n",
    "#         if state not in RESULTS.keys():\n",
    "#             RESULTS[state] = data\n",
    "#         else:\n",
    "#             RESULTS[state] = pd.concat([RESULTS[state], data], axis=1)\n",
    "\n",
    "\n",
    "#     save_pkl(os.path.join(INT_DIR, 'RESULTS.pkl'), RESULTS)\n",
    "#     print('\\nDone!\\nNumber of states processed: {}'.format(len(RESULTS)))\n",
    "# else:\n",
    "#     print('Loading previous result...')\n",
    "#     RESULTS = read_pkl(os.path.join(INT_DIR, 'RESULTS.pkl'))\n",
    "#     print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def reduce_mem_usage(props):\n",
    "    start_mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage of properties dataframe is :\",start_mem_usg,\" MB\")\n",
    "    NAlist = [] # Keeps track of columns that have missing values filled in. \n",
    "    for col in props.columns:\n",
    "        if props[col].dtype != object:  # Exclude strings\n",
    "            \n",
    "            # Print current column type\n",
    "            #print(\"******************************\")\n",
    "            #print(\"Column: \",col)\n",
    "            #print(\"dtype before: \",props[col].dtype)\n",
    "            \n",
    "            # make variables for Int, max and min\n",
    "            IsInt = False\n",
    "            mx = props[col].max()\n",
    "            mn = props[col].min()\n",
    "            \n",
    "            # Integer does not support NA, therefore, NA needs to be filled\n",
    "            if not np.isfinite(props[col]).all(): \n",
    "                NAlist.append(col)\n",
    "                props[col].fillna(mn-1,inplace=True)  \n",
    "                   \n",
    "            # test if column can be converted to an integer\n",
    "            asint = props[col].fillna(0).astype(np.int64)\n",
    "            result = (props[col] - asint)\n",
    "            result = result.sum()\n",
    "            if result > -0.01 and result < 0.01:\n",
    "                IsInt = True\n",
    "\n",
    "            \n",
    "            # Make Integer/unsigned Integer datatypes\n",
    "            if IsInt:\n",
    "                if mn >= 0:\n",
    "                    if mx < 255:\n",
    "                        props[col] = props[col].astype(np.uint8)\n",
    "                    elif mx < 65535:\n",
    "                        props[col] = props[col].astype(np.uint16)\n",
    "                    elif mx < 4294967295:\n",
    "                        props[col] = props[col].astype(np.uint32)\n",
    "                    else:\n",
    "                        props[col] = props[col].astype(np.uint64)\n",
    "                else:\n",
    "                    if mn > np.iinfo(np.int8).min and mx < np.iinfo(np.int8).max:\n",
    "                        props[col] = props[col].astype(np.int8)\n",
    "                    elif mn > np.iinfo(np.int16).min and mx < np.iinfo(np.int16).max:\n",
    "                        props[col] = props[col].astype(np.int16)\n",
    "                    elif mn > np.iinfo(np.int32).min and mx < np.iinfo(np.int32).max:\n",
    "                        props[col] = props[col].astype(np.int32)\n",
    "                    elif mn > np.iinfo(np.int64).min and mx < np.iinfo(np.int64).max:\n",
    "                        props[col] = props[col].astype(np.int64)    \n",
    "            \n",
    "            # Make float datatypes 32 bit\n",
    "            else:\n",
    "                props[col] = props[col].astype(np.float32)\n",
    "            \n",
    "            # Print new column type\n",
    "            #print(\"dtype after: \",props[col].dtype)\n",
    "            #print(\"******************************\")\n",
    "    \n",
    "    # Print final result\n",
    "    #print(\"___MEMORY USAGE AFTER COMPLETION:___\")\n",
    "    mem_usg = props.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage is: \",mem_usg,\" MB\")\n",
    "    print(\"This is \",100*mem_usg/start_mem_usg,\"% of the initial size\")\n",
    "    return props, NAlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ct\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 410.9174966812134  MB\n",
      "Memory usage is:  220.1667022705078  MB\n",
      "This is  53.57929609926331 % of the initial size\n",
      "\n",
      "oh\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 1883.4229431152344  MB\n",
      "Memory usage is:  1060.9062881469727  MB\n",
      "This is  56.32862719576963 % of the initial size\n",
      "\n",
      "ks\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 1347.2735967636108  MB\n",
      "Memory usage is:  712.0222883224487  MB\n",
      "This is  52.849123595448766 % of the initial size\n",
      "\n",
      "wv\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 523.7910432815552  MB\n",
      "Memory usage is:  266.61621856689453  MB\n",
      "This is  50.9012557558338 % of the initial size\n",
      "\n",
      "in\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 1262.8244104385376  MB\n",
      "Memory usage is:  692.3289947509766  MB\n",
      "This is  54.823852708909335 % of the initial size\n",
      "\n",
      "dc\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 10.298748016357422  MB\n",
      "Memory usage is:  4.922075271606445  MB\n",
      "This is  47.7929478786038 % of the initial size\n",
      "\n",
      "va\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 991.1451988220215  MB\n",
      "Memory usage is:  554.9209442138672  MB\n",
      "This is  55.987855752456056 % of the initial size\n",
      "\n",
      "az\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 573.2247133255005  MB\n",
      "Memory usage is:  319.29602813720703  MB\n",
      "This is  55.7017205843841 % of the initial size\n",
      "\n",
      "nd\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 1062.8240203857422  MB\n",
      "Memory usage is:  524.849967956543  MB\n",
      "This is  49.3825843121285 % of the initial size\n",
      "\n",
      "nj\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 754.2755298614502  MB\n",
      "Memory usage is:  423.49010848999023  MB\n",
      "This is  56.14528003682943 % of the initial size\n",
      "\n",
      "md\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 622.4524097442627  MB\n",
      "Memory usage is:  342.6617183685303  MB\n",
      "This is  55.050267780200954 % of the initial size\n",
      "\n",
      "ga\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 1142.1238660812378  MB\n",
      "Memory usage is:  644.3686103820801  MB\n",
      "This is  56.418452456736155 % of the initial size\n",
      "\n",
      "sd\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 921.1141662597656  MB\n",
      "Memory usage is:  457.2710876464844  MB\n",
      "This is  49.64325860965298 % of the initial size\n",
      "\n",
      "tx\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 2425.545524597168  MB\n",
      "Memory usage is:  1434.086051940918  MB\n",
      "This is  59.12426863969455 % of the initial size\n",
      "\n",
      "de\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 110.1960039138794  MB\n",
      "Memory usage is:  55.09831428527832  MB\n",
      "This is  50.0002834298228 % of the initial size\n",
      "\n",
      "mo\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 1714.3185968399048  MB\n",
      "Memory usage is:  936.4741382598877  MB\n",
      "This is  54.626610245384995 % of the initial size\n",
      "\n",
      "ma\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 746.6545057296753  MB\n",
      "Memory usage is:  414.6099042892456  MB\n",
      "This is  55.52901658097731 % of the initial size\n",
      "\n",
      "wa\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 816.479564666748  MB\n",
      "Memory usage is:  456.91770935058594  MB\n",
      "This is  55.96192839646638 % of the initial size\n",
      "\n",
      "co\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 608.2402296066284  MB\n",
      "Memory usage is:  333.69731521606445  MB\n",
      "This is  54.862749777646066 % of the initial size\n",
      "\n",
      "me\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 561.4842166900635  MB\n",
      "Memory usage is:  283.0390148162842  MB\n",
      "This is  50.409077655787485 % of the initial size\n",
      "\n",
      "hi\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 268.1777744293213  MB\n",
      "Memory usage is:  137.46197891235352  MB\n",
      "This is  51.25778197125797 % of the initial size\n",
      "\n",
      "id\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 368.89887714385986  MB\n",
      "Memory usage is:  188.96979904174805  MB\n",
      "This is  51.22536574380933 % of the initial size\n",
      "\n",
      "sc\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 626.7778558731079  MB\n",
      "Memory usage is:  338.6903419494629  MB\n",
      "This is  54.03674344519779 % of the initial size\n",
      "\n",
      "ia\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 1687.9539728164673  MB\n",
      "Memory usage is:  889.4897985458374  MB\n",
      "This is  52.69633016483634 % of the initial size\n",
      "\n",
      "nc\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 1433.370572090149  MB\n",
      "Memory usage is:  808.2142820358276  MB\n",
      "This is  56.385578005643374 % of the initial size\n",
      "\n",
      "nh\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 404.5323143005371  MB\n",
      "Memory usage is:  204.21696090698242  MB\n",
      "This is  50.48223681712224 % of the initial size\n",
      "\n",
      "al\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 869.208812713623  MB\n",
      "Memory usage is:  467.1767997741699  MB\n",
      "This is  53.74736115659817 % of the initial size\n",
      "\n",
      "il\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 2282.1878814697266  MB\n",
      "Memory usage is:  1304.2176055908203  MB\n",
      "This is  57.14768780346452 % of the initial size\n",
      "\n",
      "nv\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 235.83991527557373  MB\n",
      "Memory usage is:  125.93661785125732  MB\n",
      "This is  53.399195680724006 % of the initial size\n",
      "\n",
      "ny\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 1652.5265092849731  MB\n",
      "Memory usage is:  970.6706705093384  MB\n",
      "This is  58.73858392319135 % of the initial size\n",
      "\n",
      "ok\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 1185.1723537445068  MB\n",
      "Memory usage is:  638.392656326294  MB\n",
      "This is  53.864963548071024 % of the initial size\n",
      "\n",
      "vt\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 318.64131259918213  MB\n",
      "Memory usage is:  155.86326789855957  MB\n",
      "This is  48.914959151771846 % of the initial size\n",
      "\n",
      "ak\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 610.5059394836426  MB\n",
      "Memory usage is:  304.10680389404297  MB\n",
      "This is  49.81225967289561 % of the initial size\n",
      "\n",
      "fl\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 1067.1494665145874  MB\n",
      "Memory usage is:  623.4883947372437  MB\n",
      "This is  58.42559213130815 % of the initial size\n",
      "\n",
      "ut\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 393.8216857910156  MB\n",
      "Memory usage is:  208.23528289794922  MB\n",
      "This is  52.87552473899338 % of the initial size\n",
      "\n",
      "pr\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 834.3992700576782  MB\n",
      "Memory usage is:  440.7216053009033  MB\n",
      "This is  52.81903054282852 % of the initial size\n",
      "\n",
      "ar\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 1167.0466747283936  MB\n",
      "Memory usage is:  615.412260055542  MB\n",
      "This is  52.7324462150382 % of the initial size\n",
      "\n",
      "wy\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 252.52377891540527  MB\n",
      "Memory usage is:  123.44240951538086  MB\n",
      "This is  48.88347942739036 % of the initial size\n",
      "\n",
      "ms\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 741.5051651000977  MB\n",
      "Memory usage is:  387.8689956665039  MB\n",
      "This is  52.30833363300234 % of the initial size\n",
      "\n",
      "pa\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 2409.685555458069  MB\n",
      "Memory usage is:  1369.872130393982  MB\n",
      "This is  56.84858455042597 % of the initial size\n",
      "\n",
      "mi\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 1458.4993543624878  MB\n",
      "Memory usage is:  816.9133863449097  MB\n",
      "This is  56.01054151319688 % of the initial size\n",
      "\n",
      "ri\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 129.5575246810913  MB\n",
      "Memory usage is:  65.29859924316406  MB\n",
      "This is  50.40124022429264 % of the initial size\n",
      "\n",
      "wi\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 1552.629301071167  MB\n",
      "Memory usage is:  847.0848197937012  MB\n",
      "This is  54.558085385178096 % of the initial size\n",
      "\n",
      "ky\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 877.035810470581  MB\n",
      "Memory usage is:  469.7308807373047  MB\n",
      "This is  53.55891687994662 % of the initial size\n",
      "\n",
      "mn\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 1919.880274772644  MB\n",
      "Memory usage is:  1048.0099267959595  MB\n",
      "This is  54.58725424532354 % of the initial size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mt\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 566.8395309448242  MB\n",
      "Memory usage is:  282.86998748779297  MB\n",
      "This is  49.90300994291934 % of the initial size\n",
      "\n",
      "ca\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 1892.6917562484741  MB\n",
      "Memory usage is:  1143.5949726104736  MB\n",
      "This is  60.4216174575202 % of the initial size\n",
      "\n",
      "la\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 876.6238632202148  MB\n",
      "Memory usage is:  471.6411361694336  MB\n",
      "This is  53.8019960393154 % of the initial size\n",
      "\n",
      "tn\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 1005.1514053344727  MB\n",
      "Memory usage is:  550.5414962768555  MB\n",
      "This is  54.771996870825454 % of the initial size\n",
      "\n",
      "nm\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 575.9023704528809  MB\n",
      "Memory usage is:  301.0022964477539  MB\n",
      "This is  52.26620203196078 % of the initial size\n",
      "\n",
      "us\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 9002.16076374054  MB\n",
      "Memory usage is:  4372.892565727234  MB\n",
      "This is  48.57603280470886 % of the initial size\n",
      "\n",
      "or\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 559.2185068130493  MB\n",
      "Memory usage is:  302.2818660736084  MB\n",
      "This is  54.05433875861754 % of the initial size\n",
      "\n",
      "ne\n",
      "\n",
      "Percent complete: 100.0%\n",
      "Memory usage of properties dataframe is : 1044.904314994812  MB\n",
      "Memory usage is:  540.0697546005249  MB\n",
      "This is  51.68604884201348 % of the initial size\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sf_e_files = [x for x in sf_files if x[0]=='e']\n",
    "states = set()\n",
    "for i, f in enumerate(sf_e_files):\n",
    "    # get state\n",
    "    state = f[6:8]\n",
    "    # get sequence\n",
    "    states.update([state])\n",
    "\n",
    "# build dataframes by state, then later all data will be concatenated\n",
    "# This makes things more efficient due to the large volume of tables.\n",
    "for ST in states:\n",
    "    print(ST+'\\n')\n",
    "    RESULTS = {}\n",
    "    sf_e_files = [x for x in sf_files if x[0]=='e']\n",
    "    for i, f in enumerate(sf_e_files):\n",
    "        print('\\rPercent complete: {}%'.format(round((float(i+1)/len(sf_e_files))*100., 2)), end='')\n",
    "        # get filetype\n",
    "        ftype = f[0]\n",
    "        # get path to file for reading\n",
    "        file_path = os.path.join(SF_DIR, f)\n",
    "        # get state\n",
    "        state = f[6:8]\n",
    "        if state != ST:\n",
    "            continue\n",
    "        # get sequence\n",
    "        seq = int(f[8:12])\n",
    "        # look up column names for this file\n",
    "        columns = COL_NAME_LU[seq]\n",
    "        # read the data and set the appropriate column names\n",
    "        data = pd.read_csv(file_path, header=None, names=columns, low_memory=False)\n",
    "        # drop unnecessary columns\n",
    "        data.drop(columns=['FILEID', 'FILETYPE', 'CHARITER', 'SEQUENCE'], inplace=True)\n",
    "        # set index for concatenation - needed because `.merge()` on\n",
    "        # this many files takes FOREVER.\n",
    "        data.set_index(['STUSAB','LOGRECNO'], inplace=True)\n",
    "\n",
    "        # merge data for current state\n",
    "        if ST not in RESULTS.keys():\n",
    "            RESULTS[ST] = data\n",
    "        else:\n",
    "            RESULTS[ST] = pd.concat([RESULTS[ST], data], axis=1)\n",
    "    print('')\n",
    "    RESULTS[ST], _ = reduce_mem_usage(RESULTS[ST])\n",
    "    save_pkl(os.path.join(INT_DIR, 'STATE__{}.pkl'.format(ST)), RESULTS)\n",
    "    print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ne':                  B27001_001  B27001_002  B27001_003  B27001_004  B27001_005  \\\n",
       " STUSAB LOGRECNO                                                               \n",
       " ne     1            1875468      932067       81044       77390        3654   \n",
       "        2            1385192      683229       62585       59784        2801   \n",
       "        3             490276      248838       18459       17606         853   \n",
       "        4            1543638      765582       68302       65332        2970   \n",
       "        5            1220185      603887       54477       52117        2360   \n",
       " ...                     ...         ...         ...         ...         ...   \n",
       "        7234            3130        1600          86          80           6   \n",
       "        7235             699         349          20          16           4   \n",
       "        7236            8636        4221         349         344           5   \n",
       "        7237            1992        1068          53          53           0   \n",
       "        7238               0           0           0           0           0   \n",
       " \n",
       "                  B27001_006  B27001_007  B27001_008  B27001_009  B27001_010  \\\n",
       " STUSAB LOGRECNO                                                               \n",
       " ne     1             174690      164852        9838       93554       78770   \n",
       "        2             129024      121821        7203       76578       64402   \n",
       "        3              45666       43031        2635       16976       14368   \n",
       "        4             144689      137016        7673       79985       67641   \n",
       "        5             114484      108634        5850       64670       54958   \n",
       " ...                     ...         ...         ...         ...         ...   \n",
       "        7234             332         310          22         197         151   \n",
       "        7235              56          49           7          30          28   \n",
       "        7236             740         671          69         448         398   \n",
       "        7237             245         228          17          64          43   \n",
       "        7238               0           0           0           0           0   \n",
       " \n",
       "                  ...  C24020_064  C24020_065  C24020_066  C24020_067  \\\n",
       " STUSAB LOGRECNO  ...                                                   \n",
       " ne     1         ...       25345       62291        2619        1091   \n",
       "        2         ...       19561       45501        1381         422   \n",
       "        3         ...        5784       16790        1238         669   \n",
       "        4         ...       21642       51944        1796         623   \n",
       "        5         ...       17552       41586        1175         321   \n",
       " ...              ...         ...         ...         ...         ...   \n",
       "        7234      ...          22         104           0           0   \n",
       "        7235      ...          11          38           2           0   \n",
       "        7236      ...         147         316          20           0   \n",
       "        7237      ...          40          91           3           3   \n",
       "        7238      ...           0           0           0           0   \n",
       " \n",
       "                  C24020_068  C24020_069  C24020_070  C24020_071  C24020_072  \\\n",
       " STUSAB LOGRECNO                                                               \n",
       " ne     1                720         808       22284       15118        1916   \n",
       "        2                421         538       17275       11921        1288   \n",
       "        3                299         270        5009        3197         628   \n",
       "        4                500         673       18800       12944        1495   \n",
       "        5                394         460       12780        8452        1147   \n",
       " ...                     ...         ...         ...         ...         ...   \n",
       "        7234               0           0          60          53           0   \n",
       "        7235               2           0          11           8           0   \n",
       "        7236               0          20          75          30           4   \n",
       "        7237               0           0           3           0           0   \n",
       "        7238               0           0           0           0           0   \n",
       " \n",
       "                  C24020_073  \n",
       " STUSAB LOGRECNO              \n",
       " ne     1               5250  \n",
       "        2               4066  \n",
       "        3               1184  \n",
       "        4               4361  \n",
       "        5               3181  \n",
       " ...                     ...  \n",
       "        7234               7  \n",
       "        7235               3  \n",
       "        7236              41  \n",
       "        7237               3  \n",
       "        7238               0  \n",
       " \n",
       " [5073 rows x 26996 columns]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating results...\n",
      "(3964, 26998)\n",
      "(15663, 26998)\n",
      "(17658, 26998)\n",
      "(23324, 26998)\n",
      "(31519, 26998)\n",
      "(36592, 26998)\n",
      "(39614, 26998)\n",
      "(40243, 26998)\n",
      "(42958, 26998)\n",
      "(52102, 26998)\n",
      "(55145, 26998)\n",
      "(56936, 26998)\n",
      "(58162, 26998)\n",
      "(62382, 26998)\n",
      "(66044, 26998)\n",
      "(73582, 26998)\n",
      "(76535, 26998)\n",
      "(78082, 26998)\n",
      "(82340, 26998)\n",
      "(91661, 26998)\n",
      "(100850, 26998)\n",
      "(102814, 26998)\n",
      "(108568, 26998)\n",
      "(111364, 26998)\n",
      "(114147, 26998)\n",
      "(157852, 26998)\n",
      "(162732, 26998)\n",
      "(167913, 26998)\n"
     ]
    }
   ],
   "source": [
    "print('Concatenating results...')\n",
    "INT_STATE_FILES = [x for x in os.listdir(INT_DIR) if x.startswith('STATE__')]\n",
    "ESTIMATES = pd.DataFrame()\n",
    "\n",
    "# Reset indicies\n",
    "for i, STATE_FILE in enumerate(INT_STATE_FILES):\n",
    "    df = list(pd.read_pickle(os.path.join(INT_DIR, STATE_FILE)).values())[0]\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # Concatenate tables from different states\n",
    "    ESTIMATES = pd.concat([ESTIMATES, df])\n",
    "    print(ESTIMATES.shape)    \n",
    "ESTIMATES.to_pickle(os.path.join(INT_DIR, 'ESTIMATES.pkl'))\n",
    "\n",
    "del RESULTS # free up some memory, we don't need those anymore.\n",
    "ESTIMATES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geo Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build 'Geo' Data Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data dictionary of encoded column name: description\n",
    "file_path = os.path.join(SF_TEMPLATE_DIR, '2019_SFGeoFileTemplate.xlsx')\n",
    "template_data = pd.read_excel(file_path)\n",
    "GEO_COLS = template_data.columns\n",
    "GEO_DATA_DICT_dict = dict(zip(GEO_COLS, template_data.iloc[0]))\n",
    "    \n",
    "GEO_DATA_DICT = pd.Series(GEO_DATA_DICT_dict).reset_index()\n",
    "GEO_DATA_DICT.columns = ['column', 'description']\n",
    "GEO_DATA_DICT.to_pickle(os.path.join(INT_DIR, 'GEO_DATA_DICT.pkl'))\n",
    "GEO_DATA_DICT.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RECALC_DATA:\n",
    "    GEO_TABLE = pd.DataFrame()\n",
    "    sf_g_files = [x for x in sf_files if x[0]=='g' and x.endswith('.csv')]\n",
    "    columns = GEO_COLS\n",
    "\n",
    "    for i, f in enumerate(sf_g_files):\n",
    "        print('\\rPercent complete: {}%'.format(round((float(i+1)/len(sf_g_files))*100., 2)), end='')\n",
    "        # get filetype\n",
    "        ftype = f[0]\n",
    "        # get path to file for reading\n",
    "        file_path = os.path.join(SF_DIR, f)\n",
    "        # get state\n",
    "        state = f.split('.')[0][-2:]\n",
    "\n",
    "        # read the data and set the appropriate column names\n",
    "        try:\n",
    "            data = pd.read_csv(file_path, header=None, names=columns, encoding=\"ISO-8859-1\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('\\nFailure on file {}\\n'.format(f))\n",
    "            continue\n",
    "\n",
    "        GEO_TABLE = GEO_TABLE.append(data)\n",
    "\n",
    "\n",
    "    save_pkl(os.path.join(INT_DIR, 'GEO_TABLE.pkl'), GEO_TABLE)\n",
    "    print('\\nDone!')\n",
    "else:\n",
    "    print('Loading previous result...')\n",
    "    GEO_TABLE = read_pkl(os.path.join(INT_DIR, 'GEO_TABLE.pkl'))\n",
    "    print('Done')\n",
    "    \n",
    "GEO_TABLE = GEO_TABLE[['STUSAB', 'LOGRECNO']+list(set(GEO_TABLE.columns)-set(['STUSAB', 'LOGRECNO']))]\n",
    "GEO_TABLE.STUSAB = GEO_TABLE.STUSAB.str.strip().str.lower()\n",
    "GEO_TABLE.columns = [x.replace('.', '') for x in GEO_TABLE.columns]\n",
    "GEO_TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEO_TABLE.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Gazeteer File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAZ_TABLE = pd.read_csv('/media/school/project/temp_2018-5-year/gaz_tract_2018/2018_Gaz_tracts_national.txt'), sep='\\t')\n",
    "GAZ_TABLE.rename(columns={'USPS': 'STUSAB'}, inplace=True)\n",
    "GAZ_TABLE.STUSAB = GAZ_TABLE.STUSAB.str.strip().str.lower()\n",
    "GAZ_TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(GAZ_TABLE.GEOID.values).intersection(set(GEO_TABLE.GEOID.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in GAZ_TABLE.STUSAB.unique():\n",
    "    print('')\n",
    "    print(state)\n",
    "    print('GAZ: {}'.format(GAZ_TABLE[GAZ_TABLE.STUSAB==state].GEOID.nunique()))\n",
    "    print('GEO: {}'.format(GEO_TABLE[GEO_TABLE.STUSAB==state].GEOID.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESTIMATES_DATA_DICT = SF_DATA_DICT[~SF_DATA_DICT.column.isin(['FILEID', 'FILETYPE', 'CHARITER', 'SEQUENCE'])].reset_index(drop=True)\n",
    "ESTIMATES_DATA_DICT.loc[ESTIMATES_DATA_DICT.column=='STUSAB', 'description'] = 'State ID'\n",
    "ESTIMATES_DATA_DICT.loc[ESTIMATES_DATA_DICT.column=='LOGRECNO', 'description'] = 'Logical Record Number'\n",
    "ESTIMATES_DATA_DICT.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESTIMATES.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEO_DATA_DICT = GEO_DATA_DICT[~GEO_DATA_DICT.column.isin(['FILEID', 'FILETYPE', 'CHARITER', 'SEQUENCE'])].reset_index(drop=True)\n",
    "GEO_DATA_DICT.loc[GEO_DATA_DICT.column=='STUSAB', 'description'] = 'State ID'\n",
    "GEO_DATA_DICT.loc[GEO_DATA_DICT.column=='LOGRECNO', 'description'] = 'Logical Record Number'\n",
    "GEO_DATA_DICT.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEO_TABLE.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAZ_TABLE.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUTS = {\n",
    "    'cen_20191_estimates_dd': ESTIMATES_DATA_DICT,\n",
    "    'cen_20191_estimates': ESTIMATES,\n",
    "    'cen_20191_geo_dd': GEO_DATA_DICT,\n",
    "    'cen_20191_geo': GEO_TABLE,\n",
    "    'cen_20191_gaz': GAZ_TABLE,\n",
    "}\n",
    "\n",
    "for f, df in OUTPUTS.items():\n",
    "    print('Writing {} table'.format(f))\n",
    "    #df.to_csv(os.path.join(RES_DIR, '{}.csv'.format(f)), index=None)\n",
    "    df.to_pickle(os.path.join(RES_DIR, '{}.pkl'.format(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
