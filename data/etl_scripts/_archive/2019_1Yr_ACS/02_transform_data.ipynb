{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import reduce\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: 'C:/Users/school/Desktop/DATA_PREP_DIR/INTERMEDIATE_DATA'\n",
      "[WinError 183] Cannot create a file when that file already exists: 'C:/Users/school/Desktop/DATA_PREP_DIR/RESULTS/'\n"
     ]
    }
   ],
   "source": [
    "#################################\n",
    "WORK_DIR = 'C:/Users/school/Desktop/DATA_PREP_DIR/'\n",
    "RECALC_DATA = False # refreshes data from scratch when True, reads pickles when False\n",
    "#################################\n",
    "\n",
    "# Directories that exist\n",
    "SF_DIR = os.path.join(WORK_DIR, '2019_acs/sf')\n",
    "SF_TEMPLATE_DIR = os.path.join(WORK_DIR, '2019_acs/sf_template')\n",
    "\n",
    "# Directories created by this script\n",
    "INT_DIR = os.path.join(WORK_DIR, 'INTERMEDIATE_DATA')\n",
    "RES_DIR = os.path.join(WORK_DIR, 'RESULTS/')\n",
    "\n",
    "try:\n",
    "    os.makedirs(INT_DIR)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "try:\n",
    "    os.makedirs(RES_DIR)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pkl(file_path, data):\n",
    "    with open(file_path, 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def read_pkl(file_path):\n",
    "    with open(file_path, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary files start with e, m, or g, indicating:\n",
    "\n",
    "* e: estimates\n",
    "* m: margins of error\n",
    "* g: geography files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_files = os.listdir(SF_DIR)\n",
    "# verify present files fall into the three categories, as denoted by first letter of filename\n",
    "for first_letter in [x[0] for x in sf_files]:\n",
    "    assert first_letter in ['e', 'm', 'g']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build 'Estimates' Data Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>FILEID</td>\n",
       "      <td>FILEID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>FILETYPE</td>\n",
       "      <td>FILETYPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>STUSAB</td>\n",
       "      <td>STUSAB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CHARITER</td>\n",
       "      <td>CHARITER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>SEQUENCE</td>\n",
       "      <td>SEQUENCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35528</td>\n",
       "      <td>C23002C_023</td>\n",
       "      <td>SEX BY AGE BY EMPLOYMENT STATUS FOR THE POPULA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35529</td>\n",
       "      <td>C23002C_024</td>\n",
       "      <td>SEX BY AGE BY EMPLOYMENT STATUS FOR THE POPULA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35530</td>\n",
       "      <td>C23002C_025</td>\n",
       "      <td>SEX BY AGE BY EMPLOYMENT STATUS FOR THE POPULA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35531</td>\n",
       "      <td>C23002C_026</td>\n",
       "      <td>SEX BY AGE BY EMPLOYMENT STATUS FOR THE POPULA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35532</td>\n",
       "      <td>C23002C_027</td>\n",
       "      <td>SEX BY AGE BY EMPLOYMENT STATUS FOR THE POPULA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35533 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            column                                        description\n",
       "0           FILEID                                             FILEID\n",
       "1         FILETYPE                                           FILETYPE\n",
       "2           STUSAB                                             STUSAB\n",
       "3         CHARITER                                           CHARITER\n",
       "4         SEQUENCE                                           SEQUENCE\n",
       "...            ...                                                ...\n",
       "35528  C23002C_023  SEX BY AGE BY EMPLOYMENT STATUS FOR THE POPULA...\n",
       "35529  C23002C_024  SEX BY AGE BY EMPLOYMENT STATUS FOR THE POPULA...\n",
       "35530  C23002C_025  SEX BY AGE BY EMPLOYMENT STATUS FOR THE POPULA...\n",
       "35531  C23002C_026  SEX BY AGE BY EMPLOYMENT STATUS FOR THE POPULA...\n",
       "35532  C23002C_027  SEX BY AGE BY EMPLOYMENT STATUS FOR THE POPULA...\n",
       "\n",
       "[35533 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build data dictionary of encoded column name: description\n",
    "SF_DATA_DICT_dict = {}\n",
    "for f in os.listdir(SF_TEMPLATE_DIR):\n",
    "    if not f.startswith('seq'):\n",
    "        continue\n",
    "    file_path = os.path.join(SF_TEMPLATE_DIR, f)\n",
    "    template_data = pd.read_excel(file_path, sheet_name='e')\n",
    "    mapping = dict(zip(template_data.columns, template_data.iloc[0]))\n",
    "    SF_DATA_DICT_dict.update(mapping)\n",
    "SF_DATA_DICT = pd.Series(SF_DATA_DICT_dict).reset_index()\n",
    "SF_DATA_DICT.columns = ['column', 'description']\n",
    "SF_DATA_DICT.to_pickle(os.path.join(INT_DIR, 'SF_DATA_DICT.pkl'))\n",
    "SF_DATA_DICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build 'Estimates' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, prepare dict of {<int>seq: column names} for estimates to speed up lookups\n",
    "COL_NAME_LU = {}\n",
    "for template in os.listdir(SF_TEMPLATE_DIR):\n",
    "    if not template.startswith('seq'):\n",
    "        continue\n",
    "    seq = int(template.split('.')[0][3:])\n",
    "    columns = pd.read_excel(os.path.join(SF_TEMPLATE_DIR, template), sheet_name='e').columns\n",
    "    COL_NAME_LU[seq] = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous result...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "if RECALC_DATA:\n",
    "    # build dataframes by state, then later all data will be concatenated\n",
    "    # This makes things more efficient due to the large volume of tables.\n",
    "    RESULTS = {}\n",
    "    sf_e_files = [x for x in sf_files if x[0]=='e']\n",
    "    for i, f in enumerate(sf_e_files):\n",
    "        print('\\rPercent complete: {}%'.format(round((float(i+1)/len(sf_e_files))*100., 2)), end='')\n",
    "        # get filetype\n",
    "        ftype = f[0]\n",
    "        # get path to file for reading\n",
    "        file_path = os.path.join(SF_DIR, f)\n",
    "        # get state\n",
    "        state = f[6:8]\n",
    "        # get sequence\n",
    "        seq = int(f[8:12])\n",
    "        # look up column names for this file\n",
    "        columns = COL_NAME_LU[seq]\n",
    "        # read the data and set the appropriate column names\n",
    "        data = pd.read_csv(file_path, header=None, names=columns)\n",
    "        # drop unnecessary columns\n",
    "        data.drop(columns=['FILEID', 'FILETYPE', 'CHARITER', 'SEQUENCE'], inplace=True)\n",
    "        # set index for concatenation - needed because `.merge()` on\n",
    "        # this many files takes FOREVER.\n",
    "        data.set_index(['STUSAB','LOGRECNO'], inplace=True)\n",
    "\n",
    "        # merge data for current state\n",
    "        if state not in RESULTS.keys():\n",
    "            RESULTS[state] = data\n",
    "        else:\n",
    "            RESULTS[state] = pd.concat([RESULTS[state], data], axis=1)\n",
    "\n",
    "\n",
    "    save_pkl(os.path.join(INT_DIR, 'RESULTS.pkl'), RESULTS)\n",
    "    print('\\nDone!\\nNumber of states processed: {}'.format(len(RESULTS)))\n",
    "else:\n",
    "    print('Loading previous result...')\n",
    "    RESULTS = read_pkl(os.path.join(INT_DIR, 'RESULTS.pkl'))\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating results...\n",
      "Loading previous result...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STUSAB</th>\n",
       "      <th>LOGRECNO</th>\n",
       "      <th>B01001_001</th>\n",
       "      <th>B01001_002</th>\n",
       "      <th>B01001_003</th>\n",
       "      <th>B01001_004</th>\n",
       "      <th>B01001_005</th>\n",
       "      <th>B01001_006</th>\n",
       "      <th>B01001_007</th>\n",
       "      <th>B01001_008</th>\n",
       "      <th>...</th>\n",
       "      <th>B99282_005</th>\n",
       "      <th>B99282_006</th>\n",
       "      <th>B99282_007</th>\n",
       "      <th>B99282_008</th>\n",
       "      <th>B99282_009</th>\n",
       "      <th>B99283_001</th>\n",
       "      <th>B99283_002</th>\n",
       "      <th>B99283_003</th>\n",
       "      <th>B99283_004</th>\n",
       "      <th>B99283_005</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ak</td>\n",
       "      <td>1</td>\n",
       "      <td>731545.0</td>\n",
       "      <td>380433.0</td>\n",
       "      <td>24910.0</td>\n",
       "      <td>28292.0</td>\n",
       "      <td>25256.0</td>\n",
       "      <td>14719.0</td>\n",
       "      <td>11147.0</td>\n",
       "      <td>5181.0</td>\n",
       "      <td>...</td>\n",
       "      <td>248183</td>\n",
       "      <td>3838</td>\n",
       "      <td>248361</td>\n",
       "      <td>3849</td>\n",
       "      <td>248350</td>\n",
       "      <td>252199</td>\n",
       "      <td>7194</td>\n",
       "      <td>7194</td>\n",
       "      <td>10098</td>\n",
       "      <td>239283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ak</td>\n",
       "      <td>2</td>\n",
       "      <td>474992.0</td>\n",
       "      <td>240654.0</td>\n",
       "      <td>15669.0</td>\n",
       "      <td>17866.0</td>\n",
       "      <td>15164.0</td>\n",
       "      <td>9242.0</td>\n",
       "      <td>7846.0</td>\n",
       "      <td>3480.0</td>\n",
       "      <td>...</td>\n",
       "      <td>166396</td>\n",
       "      <td>2680</td>\n",
       "      <td>166398</td>\n",
       "      <td>2693</td>\n",
       "      <td>166385</td>\n",
       "      <td>169078</td>\n",
       "      <td>4779</td>\n",
       "      <td>4779</td>\n",
       "      <td>7555</td>\n",
       "      <td>159895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ak</td>\n",
       "      <td>3</td>\n",
       "      <td>256553.0</td>\n",
       "      <td>139779.0</td>\n",
       "      <td>9241.0</td>\n",
       "      <td>10426.0</td>\n",
       "      <td>10092.0</td>\n",
       "      <td>5477.0</td>\n",
       "      <td>3301.0</td>\n",
       "      <td>1701.0</td>\n",
       "      <td>...</td>\n",
       "      <td>81787</td>\n",
       "      <td>1158</td>\n",
       "      <td>81963</td>\n",
       "      <td>1156</td>\n",
       "      <td>81965</td>\n",
       "      <td>83121</td>\n",
       "      <td>2415</td>\n",
       "      <td>2415</td>\n",
       "      <td>2543</td>\n",
       "      <td>79388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ak</td>\n",
       "      <td>4</td>\n",
       "      <td>539488.0</td>\n",
       "      <td>277116.0</td>\n",
       "      <td>17803.0</td>\n",
       "      <td>21038.0</td>\n",
       "      <td>17743.0</td>\n",
       "      <td>10793.0</td>\n",
       "      <td>8374.0</td>\n",
       "      <td>4095.0</td>\n",
       "      <td>...</td>\n",
       "      <td>188899</td>\n",
       "      <td>3050</td>\n",
       "      <td>188904</td>\n",
       "      <td>3079</td>\n",
       "      <td>188875</td>\n",
       "      <td>191954</td>\n",
       "      <td>5649</td>\n",
       "      <td>5649</td>\n",
       "      <td>8298</td>\n",
       "      <td>181453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ak</td>\n",
       "      <td>5</td>\n",
       "      <td>493166.0</td>\n",
       "      <td>254154.0</td>\n",
       "      <td>16238.0</td>\n",
       "      <td>19841.0</td>\n",
       "      <td>16232.0</td>\n",
       "      <td>9966.0</td>\n",
       "      <td>8068.0</td>\n",
       "      <td>3884.0</td>\n",
       "      <td>...</td>\n",
       "      <td>170727</td>\n",
       "      <td>2790</td>\n",
       "      <td>170700</td>\n",
       "      <td>2806</td>\n",
       "      <td>170684</td>\n",
       "      <td>173490</td>\n",
       "      <td>5312</td>\n",
       "      <td>5312</td>\n",
       "      <td>7780</td>\n",
       "      <td>163671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>wy</td>\n",
       "      <td>17</td>\n",
       "      <td>138380.0</td>\n",
       "      <td>71563.0</td>\n",
       "      <td>3983.0</td>\n",
       "      <td>5431.0</td>\n",
       "      <td>3128.0</td>\n",
       "      <td>2544.0</td>\n",
       "      <td>2638.0</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>...</td>\n",
       "      <td>56945</td>\n",
       "      <td>563</td>\n",
       "      <td>56945</td>\n",
       "      <td>623</td>\n",
       "      <td>56885</td>\n",
       "      <td>57508</td>\n",
       "      <td>1296</td>\n",
       "      <td>1296</td>\n",
       "      <td>3628</td>\n",
       "      <td>53564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>wy</td>\n",
       "      <td>18</td>\n",
       "      <td>108730.0</td>\n",
       "      <td>54849.0</td>\n",
       "      <td>3410.0</td>\n",
       "      <td>3336.0</td>\n",
       "      <td>4853.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>869.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45296</td>\n",
       "      <td>339</td>\n",
       "      <td>45296</td>\n",
       "      <td>449</td>\n",
       "      <td>45186</td>\n",
       "      <td>45635</td>\n",
       "      <td>1145</td>\n",
       "      <td>1145</td>\n",
       "      <td>2471</td>\n",
       "      <td>42299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>wy</td>\n",
       "      <td>19</td>\n",
       "      <td>118373.0</td>\n",
       "      <td>60147.0</td>\n",
       "      <td>4488.0</td>\n",
       "      <td>5277.0</td>\n",
       "      <td>4274.0</td>\n",
       "      <td>2402.0</td>\n",
       "      <td>1923.0</td>\n",
       "      <td>971.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42101</td>\n",
       "      <td>62</td>\n",
       "      <td>42101</td>\n",
       "      <td>230</td>\n",
       "      <td>41933</td>\n",
       "      <td>42163</td>\n",
       "      <td>652</td>\n",
       "      <td>652</td>\n",
       "      <td>1926</td>\n",
       "      <td>39900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>wy</td>\n",
       "      <td>20</td>\n",
       "      <td>91520.0</td>\n",
       "      <td>46495.0</td>\n",
       "      <td>2777.0</td>\n",
       "      <td>3807.0</td>\n",
       "      <td>2237.0</td>\n",
       "      <td>1636.0</td>\n",
       "      <td>1164.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>...</td>\n",
       "      <td>38639</td>\n",
       "      <td>332</td>\n",
       "      <td>38639</td>\n",
       "      <td>392</td>\n",
       "      <td>38579</td>\n",
       "      <td>38971</td>\n",
       "      <td>1036</td>\n",
       "      <td>1036</td>\n",
       "      <td>2968</td>\n",
       "      <td>35756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>wy</td>\n",
       "      <td>21</td>\n",
       "      <td>79858.0</td>\n",
       "      <td>40278.0</td>\n",
       "      <td>2271.0</td>\n",
       "      <td>2417.0</td>\n",
       "      <td>4097.0</td>\n",
       "      <td>1802.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32705</td>\n",
       "      <td>339</td>\n",
       "      <td>32705</td>\n",
       "      <td>449</td>\n",
       "      <td>32595</td>\n",
       "      <td>33044</td>\n",
       "      <td>1059</td>\n",
       "      <td>1059</td>\n",
       "      <td>1684</td>\n",
       "      <td>30507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7952 rows × 35529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STUSAB  LOGRECNO  B01001_001  B01001_002  B01001_003  B01001_004  \\\n",
       "0      ak         1    731545.0    380433.0     24910.0     28292.0   \n",
       "1      ak         2    474992.0    240654.0     15669.0     17866.0   \n",
       "2      ak         3    256553.0    139779.0      9241.0     10426.0   \n",
       "3      ak         4    539488.0    277116.0     17803.0     21038.0   \n",
       "4      ak         5    493166.0    254154.0     16238.0     19841.0   \n",
       "..    ...       ...         ...         ...         ...         ...   \n",
       "16     wy        17    138380.0     71563.0      3983.0      5431.0   \n",
       "17     wy        18    108730.0     54849.0      3410.0      3336.0   \n",
       "18     wy        19    118373.0     60147.0      4488.0      5277.0   \n",
       "19     wy        20     91520.0     46495.0      2777.0      3807.0   \n",
       "20     wy        21     79858.0     40278.0      2271.0      2417.0   \n",
       "\n",
       "    B01001_005  B01001_006  B01001_007  B01001_008  ...  B99282_005  \\\n",
       "0      25256.0     14719.0     11147.0      5181.0  ...      248183   \n",
       "1      15164.0      9242.0      7846.0      3480.0  ...      166396   \n",
       "2      10092.0      5477.0      3301.0      1701.0  ...       81787   \n",
       "3      17743.0     10793.0      8374.0      4095.0  ...      188899   \n",
       "4      16232.0      9966.0      8068.0      3884.0  ...      170727   \n",
       "..         ...         ...         ...         ...  ...         ...   \n",
       "16      3128.0      2544.0      2638.0      1927.0  ...       56945   \n",
       "17      4853.0      2200.0      1222.0       869.0  ...       45296   \n",
       "18      4274.0      2402.0      1923.0       971.0  ...       42101   \n",
       "19      2237.0      1636.0      1164.0       599.0  ...       38639   \n",
       "20      4097.0      1802.0       806.0       753.0  ...       32705   \n",
       "\n",
       "    B99282_006  B99282_007  B99282_008  B99282_009  B99283_001  B99283_002  \\\n",
       "0         3838      248361        3849      248350      252199        7194   \n",
       "1         2680      166398        2693      166385      169078        4779   \n",
       "2         1158       81963        1156       81965       83121        2415   \n",
       "3         3050      188904        3079      188875      191954        5649   \n",
       "4         2790      170700        2806      170684      173490        5312   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "16         563       56945         623       56885       57508        1296   \n",
       "17         339       45296         449       45186       45635        1145   \n",
       "18          62       42101         230       41933       42163         652   \n",
       "19         332       38639         392       38579       38971        1036   \n",
       "20         339       32705         449       32595       33044        1059   \n",
       "\n",
       "    B99283_003  B99283_004  B99283_005  \n",
       "0         7194       10098      239283  \n",
       "1         4779        7555      159895  \n",
       "2         2415        2543       79388  \n",
       "3         5649        8298      181453  \n",
       "4         5312        7780      163671  \n",
       "..         ...         ...         ...  \n",
       "16        1296        3628       53564  \n",
       "17        1145        2471       42299  \n",
       "18         652        1926       39900  \n",
       "19        1036        2968       35756  \n",
       "20        1059        1684       30507  \n",
       "\n",
       "[7952 rows x 35529 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Concatenating results...')\n",
    "\n",
    "if RECALC_DATA:\n",
    "    # Reset indicies\n",
    "    for i, (state, df) in enumerate(RESULTS.items()):\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "    # Concatenate tables from different states\n",
    "    ESTIMATES = pd.concat([df for df in RESULTS.values()])\n",
    "    ESTIMATES.to_pickle(os.path.join(INT_DIR, 'ESTIMATES.pkl'))\n",
    "else:\n",
    "    print('Loading previous result...')\n",
    "    ESTIMATES = pd.read_pickle(os.path.join(INT_DIR, 'ESTIMATES.pkl'))\n",
    "    print('Done')    \n",
    "\n",
    "del RESULTS # free up some memory, we don't need those anymore.\n",
    "ESTIMATES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The MINI GEO file appears to be a subset of the data contained in the 'g' files.\n",
    "# Therefore, this file will be ignored for now and the 'g' files used instead.\n",
    "\n",
    "# GEO_PATH = os.path.join(WORK_DIR, '2019_acs/geo/1_year_Mini_Geo.xlsx')\n",
    "# geo = pd.read_excel(GEO_PATH, sheet_name=None)\n",
    "# geo[list(geo.keys())[5]]\n",
    "\n",
    "# # Combine all sheets from geo file into single table\n",
    "# for i, (sheet, data) in enumerate(geo.items()):\n",
    "#     print('\\rPercent complete: {}%'.format(round((float(i+1)/len(geo))*100., 2)), end='')\n",
    "#     # rename columns so state and log rec no are the same names\n",
    "#     data.rename(columns={\n",
    "#         'State': 'STUSAB',\n",
    "#         'Logical Record Number': 'LOGRECNO',\n",
    "#         'Geography ID': 'GEOID',\n",
    "#         'Geography Name': 'GEONAME'}, inplace=True)\n",
    "#     # set the state abbrev to lowercase to match the summary data for the join\n",
    "#     data.STUSAB = data.STUSAB.str.strip().str.lower()\n",
    "\n",
    "# geo_prep = pd.concat(geo.values())\n",
    "# geo_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build 'Geo' Data Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>FILEID</td>\n",
       "      <td>Always equal to ACS Summary File identification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>STUSAB</td>\n",
       "      <td>State Postal Abbreviation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>SUMLEVEL</td>\n",
       "      <td>Summary Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>COMPONENT</td>\n",
       "      <td>Geographic Component</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LOGRECNO</td>\n",
       "      <td>Logical Record Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>REGION</td>\n",
       "      <td>Census Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>DIVISION</td>\n",
       "      <td>Census Division</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>STATECE</td>\n",
       "      <td>State (Census Code)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>STATE</td>\n",
       "      <td>State (FIPS Code)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      column                                      description\n",
       "0     FILEID  Always equal to ACS Summary File identification\n",
       "1     STUSAB                        State Postal Abbreviation\n",
       "2   SUMLEVEL                                    Summary Level\n",
       "3  COMPONENT                             Geographic Component\n",
       "4   LOGRECNO                            Logical Record Number\n",
       "5         US                                              US \n",
       "6     REGION                                    Census Region\n",
       "7   DIVISION                                  Census Division\n",
       "8    STATECE                              State (Census Code)\n",
       "9      STATE                                State (FIPS Code)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build data dictionary of encoded column name: description\n",
    "file_path = os.path.join(SF_TEMPLATE_DIR, '2019_SFGeoFileTemplate.xlsx')\n",
    "template_data = pd.read_excel(file_path)\n",
    "GEO_COLS = template_data.columns\n",
    "GEO_DATA_DICT_dict = dict(zip(GEO_COLS, template_data.iloc[0]))\n",
    "    \n",
    "GEO_DATA_DICT = pd.Series(GEO_DATA_DICT_dict).reset_index()\n",
    "GEO_DATA_DICT.columns = ['column', 'description']\n",
    "GEO_DATA_DICT.to_pickle(os.path.join(INT_DIR, 'SF_DATA_DICT.pkl'))\n",
    "GEO_DATA_DICT.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if RECALC_DATA:\n",
    "#     # Merge geo data into ESTIMATES\n",
    "#     ESTIMATES_GEO = ESTIMATES.sort_index(axis=1).merge(geo_prep, on=['STUSAB', 'LOGRECNO'], how='left')\n",
    "\n",
    "#     # reorder columns\n",
    "#     info_cols = ['STUSAB', 'LOGRECNO', 'GEOID', 'GEONAME']\n",
    "#     all_other_cols = sorted(list(set(ESTIMATES_GEO.columns)-set(info_cols)))\n",
    "#     ESTIMATES_GEO = ESTIMATES_GEO[info_cols + all_other_cols]\n",
    "#     ESTIMATES_GEO.to_pickle(os.path.join(INT_DIR, 'ESTIMATES_GEO.pkl'))\n",
    "# else:\n",
    "#     print('Loading previous result...')\n",
    "#     ESTIMATES_GEO = pd.read_pickle(os.path.join(INT_DIR, 'ESTIMATES_GEO.pkl'))\n",
    "#     print('Done')        \n",
    "\n",
    "# ESTIMATES_GEO.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous result...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STUSAB</th>\n",
       "      <th>LOGRECNO</th>\n",
       "      <th>NECTADIV</th>\n",
       "      <th>BLANK1</th>\n",
       "      <th>CDCURR</th>\n",
       "      <th>PCI</th>\n",
       "      <th>COMPONENT</th>\n",
       "      <th>COUSUB</th>\n",
       "      <th>US</th>\n",
       "      <th>PLACE</th>\n",
       "      <th>...</th>\n",
       "      <th>AIHHTLI</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>BLKGRP</th>\n",
       "      <th>ZCTA5</th>\n",
       "      <th>STATECE</th>\n",
       "      <th>AITSCE</th>\n",
       "      <th>REGION</th>\n",
       "      <th>MEMI</th>\n",
       "      <th>BLANK4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ak</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ak</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ak</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ak</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ak</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>wy</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>wy</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>wy</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>wy</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>wy</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7952 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STUSAB  LOGRECNO  NECTADIV  BLANK1  CDCURR  PCI COMPONENT  COUSUB  US  \\\n",
       "0      ak         1       NaN     NaN     NaN  NaN        00     NaN NaN   \n",
       "1      ak         2       NaN     NaN     NaN  NaN        01     NaN NaN   \n",
       "2      ak         3       NaN     NaN     NaN  NaN        43     NaN NaN   \n",
       "3      ak         4       NaN     NaN     NaN  NaN        A0     NaN NaN   \n",
       "4      ak         5       NaN     NaN     NaN  NaN        C0     NaN NaN   \n",
       "..    ...       ...       ...     ...     ...  ...       ...     ...  ..   \n",
       "16     wy        17       NaN     NaN     NaN  NaN        00     NaN NaN   \n",
       "17     wy        18       NaN     NaN     NaN  NaN        00     NaN NaN   \n",
       "18     wy        19       NaN     NaN     NaN  NaN        00     NaN NaN   \n",
       "19     wy        20       NaN     NaN     NaN  NaN        00     NaN NaN   \n",
       "20     wy        21       NaN     NaN     NaN  NaN        00     NaN NaN   \n",
       "\n",
       "    PLACE  ...  AIHHTLI  STATE  COUNTY  BLKGRP  ZCTA5  STATECE  AITSCE REGION  \\\n",
       "0     NaN  ...      NaN    2.0     NaN     NaN    NaN      NaN     NaN    NaN   \n",
       "1     NaN  ...      NaN    2.0     NaN     NaN    NaN      NaN     NaN    NaN   \n",
       "2     NaN  ...      NaN    2.0     NaN     NaN    NaN      NaN     NaN    NaN   \n",
       "3     NaN  ...      NaN    2.0     NaN     NaN    NaN      NaN     NaN    NaN   \n",
       "4     NaN  ...      NaN    2.0     NaN     NaN    NaN      NaN     NaN    NaN   \n",
       "..    ...  ...      ...    ...     ...     ...    ...      ...     ...    ...   \n",
       "16    NaN  ...      NaN   56.0     NaN     NaN    NaN      NaN     NaN    NaN   \n",
       "17    NaN  ...      NaN   56.0     NaN     NaN    NaN      NaN     NaN    NaN   \n",
       "18    NaN  ...      NaN   56.0     NaN     NaN    NaN      NaN     NaN    NaN   \n",
       "19    NaN  ...      NaN   56.0     NaN     NaN    NaN      NaN     NaN    NaN   \n",
       "20    NaN  ...      NaN   56.0     NaN     NaN    NaN      NaN     NaN    NaN   \n",
       "\n",
       "    MEMI BLANK4  \n",
       "0    NaN    NaN  \n",
       "1    NaN    NaN  \n",
       "2    NaN    NaN  \n",
       "3    NaN    NaN  \n",
       "4    1.0    NaN  \n",
       "..   ...    ...  \n",
       "16   NaN    NaN  \n",
       "17   NaN    NaN  \n",
       "18   NaN    NaN  \n",
       "19   NaN    NaN  \n",
       "20   NaN    NaN  \n",
       "\n",
       "[7952 rows x 53 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if RECALC_DATA:\n",
    "    GEO_TABLE = pd.DataFrame()\n",
    "    sf_g_files = [x for x in sf_files if x[0]=='g' and x.endswith('.csv')]\n",
    "    columns = GEO_COLS\n",
    "\n",
    "    for i, f in enumerate(sf_g_files):\n",
    "        print('\\rPercent complete: {}%'.format(round((float(i+1)/len(sf_g_files))*100., 2)), end='')\n",
    "        # get filetype\n",
    "        ftype = f[0]\n",
    "        # get path to file for reading\n",
    "        file_path = os.path.join(SF_DIR, f)\n",
    "        # get state\n",
    "        state = f.split('.')[0][-2:]\n",
    "\n",
    "        # read the data and set the appropriate column names\n",
    "        try:\n",
    "            data = pd.read_csv(file_path, header=None, names=columns, encoding=\"ISO-8859-1\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('\\nFailure on file {}\\n'.format(f))\n",
    "            continue\n",
    "\n",
    "        GEO_TABLE = GEO_TABLE.append(data)\n",
    "\n",
    "\n",
    "    save_pkl(os.path.join(INT_DIR, 'GEO_TABLE.pkl'), GEO_TABLE)\n",
    "    print('\\nDone!')\n",
    "else:\n",
    "    print('Loading previous result...')\n",
    "    GEO_TABLE = read_pkl(os.path.join(INT_DIR, 'GEO_TABLE.pkl'))\n",
    "    print('Done')\n",
    "    \n",
    "GEO_TABLE = GEO_TABLE[['STUSAB', 'LOGRECNO']+list(set(GEO_TABLE.columns)-set(['STUSAB', 'LOGRECNO']))]\n",
    "GEO_TABLE.STUSAB = GEO_TABLE.STUSAB.str.strip().str.lower()\n",
    "GEO_TABLE.columns = [x.replace('.', '') for x in GEO_TABLE.columns]\n",
    "GEO_TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STUSAB                    ak\n",
       "LOGRECNO                   3\n",
       "NECTADIV                 NaN\n",
       "BLANK1                   NaN\n",
       "CDCURR                   NaN\n",
       "PCI                      NaN\n",
       "COMPONENT                 43\n",
       "COUSUB                   NaN\n",
       "US                       NaN\n",
       "PLACE                    NaN\n",
       "SDUNI                    NaN\n",
       "MACC                     NaN\n",
       "BLANK2                   NaN\n",
       "METDIV                   NaN\n",
       "AIANHH                   NaN\n",
       "CSA                      NaN\n",
       "BLANK3                   NaN\n",
       "NAME         Alaska -- Rural\n",
       "SLDL                     NaN\n",
       "GEOID              04043US02\n",
       "BLANK6                   NaN\n",
       "CNECTA                   NaN\n",
       "FILEID                 ACSSF\n",
       "CONCIT                   NaN\n",
       "BLANK                    NaN\n",
       "SLDU                     NaN\n",
       "AIANHHFP                 NaN\n",
       "UA                       NaN\n",
       "UR                         R\n",
       "PUMA5                    NaN\n",
       "BLANK5                   NaN\n",
       "SUMLEVEL                  40\n",
       "SDSEC                    NaN\n",
       "DIVISION                 NaN\n",
       "AITS                     NaN\n",
       "NECTA                    NaN\n",
       "SUBMCD                   NaN\n",
       "SDELM                    NaN\n",
       "BTBG                     NaN\n",
       "ANRC                     NaN\n",
       "BTTR                     NaN\n",
       "CBSA                     NaN\n",
       "TRACT                    NaN\n",
       "AIHHTLI                  NaN\n",
       "STATE                      2\n",
       "COUNTY                   NaN\n",
       "BLKGRP                   NaN\n",
       "ZCTA5                    NaN\n",
       "STATECE                  NaN\n",
       "AITSCE                   NaN\n",
       "REGION                   NaN\n",
       "MEMI                     NaN\n",
       "BLANK4                   NaN\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GEO_TABLE.iloc[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Gazeteer File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STUSAB</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>ALAND</th>\n",
       "      <th>AWATER</th>\n",
       "      <th>ALAND_SQMI</th>\n",
       "      <th>AWATER_SQMI</th>\n",
       "      <th>INTPTLAT</th>\n",
       "      <th>INTPTLONG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>al</td>\n",
       "      <td>1001020100</td>\n",
       "      <td>9817813</td>\n",
       "      <td>28435</td>\n",
       "      <td>3.791</td>\n",
       "      <td>0.011</td>\n",
       "      <td>32.481959</td>\n",
       "      <td>-86.491338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>al</td>\n",
       "      <td>1001020200</td>\n",
       "      <td>3325680</td>\n",
       "      <td>5669</td>\n",
       "      <td>1.284</td>\n",
       "      <td>0.002</td>\n",
       "      <td>32.475758</td>\n",
       "      <td>-86.472468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>al</td>\n",
       "      <td>1001020300</td>\n",
       "      <td>5349273</td>\n",
       "      <td>9054</td>\n",
       "      <td>2.065</td>\n",
       "      <td>0.003</td>\n",
       "      <td>32.474024</td>\n",
       "      <td>-86.459703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>al</td>\n",
       "      <td>1001020400</td>\n",
       "      <td>6384276</td>\n",
       "      <td>8408</td>\n",
       "      <td>2.465</td>\n",
       "      <td>0.003</td>\n",
       "      <td>32.471030</td>\n",
       "      <td>-86.444835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>al</td>\n",
       "      <td>1001020500</td>\n",
       "      <td>11408866</td>\n",
       "      <td>43534</td>\n",
       "      <td>4.405</td>\n",
       "      <td>0.017</td>\n",
       "      <td>32.458922</td>\n",
       "      <td>-86.421826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73996</td>\n",
       "      <td>pr</td>\n",
       "      <td>72153750501</td>\n",
       "      <td>1820185</td>\n",
       "      <td>0</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.031211</td>\n",
       "      <td>-66.867347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73997</td>\n",
       "      <td>pr</td>\n",
       "      <td>72153750502</td>\n",
       "      <td>689930</td>\n",
       "      <td>0</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.000</td>\n",
       "      <td>18.024746</td>\n",
       "      <td>-66.860442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73998</td>\n",
       "      <td>pr</td>\n",
       "      <td>72153750503</td>\n",
       "      <td>3298433</td>\n",
       "      <td>1952</td>\n",
       "      <td>1.274</td>\n",
       "      <td>0.001</td>\n",
       "      <td>18.023148</td>\n",
       "      <td>-66.876603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73999</td>\n",
       "      <td>pr</td>\n",
       "      <td>72153750601</td>\n",
       "      <td>10987037</td>\n",
       "      <td>4527</td>\n",
       "      <td>4.242</td>\n",
       "      <td>0.002</td>\n",
       "      <td>18.017808</td>\n",
       "      <td>-66.839070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>pr</td>\n",
       "      <td>72153750602</td>\n",
       "      <td>17520483</td>\n",
       "      <td>252953</td>\n",
       "      <td>6.765</td>\n",
       "      <td>0.098</td>\n",
       "      <td>17.985025</td>\n",
       "      <td>-66.853531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74001 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      STUSAB        GEOID     ALAND  AWATER  ALAND_SQMI  AWATER_SQMI  \\\n",
       "0         al   1001020100   9817813   28435       3.791        0.011   \n",
       "1         al   1001020200   3325680    5669       1.284        0.002   \n",
       "2         al   1001020300   5349273    9054       2.065        0.003   \n",
       "3         al   1001020400   6384276    8408       2.465        0.003   \n",
       "4         al   1001020500  11408866   43534       4.405        0.017   \n",
       "...      ...          ...       ...     ...         ...          ...   \n",
       "73996     pr  72153750501   1820185       0       0.703        0.000   \n",
       "73997     pr  72153750502    689930       0       0.266        0.000   \n",
       "73998     pr  72153750503   3298433    1952       1.274        0.001   \n",
       "73999     pr  72153750601  10987037    4527       4.242        0.002   \n",
       "74000     pr  72153750602  17520483  252953       6.765        0.098   \n",
       "\n",
       "        INTPTLAT  \\\n",
       "0      32.481959   \n",
       "1      32.475758   \n",
       "2      32.474024   \n",
       "3      32.471030   \n",
       "4      32.458922   \n",
       "...          ...   \n",
       "73996  18.031211   \n",
       "73997  18.024746   \n",
       "73998  18.023148   \n",
       "73999  18.017808   \n",
       "74000  17.985025   \n",
       "\n",
       "       INTPTLONG                                                                                                                               \n",
       "0                                             -86.491338                                                                                       \n",
       "1                                             -86.472468                                                                                       \n",
       "2                                             -86.459703                                                                                       \n",
       "3                                             -86.444835                                                                                       \n",
       "4                                             -86.421826                                                                                       \n",
       "...                                                  ...                                                                                       \n",
       "73996                                         -66.867347                                                                                       \n",
       "73997                                         -66.860442                                                                                       \n",
       "73998                                         -66.876603                                                                                       \n",
       "73999                                         -66.839070                                                                                       \n",
       "74000                                         -66.853531                                                                                       \n",
       "\n",
       "[74001 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAZ_TABLE = pd.read_csv(os.path.join(WORK_DIR, '2019_acs/gaz_tract/2019_Gaz_tracts_national.txt'), sep='\\t')\n",
    "GAZ_TABLE.rename(columns={'USPS': 'STUSAB'}, inplace=True)\n",
    "GAZ_TABLE.STUSAB = GAZ_TABLE.STUSAB.str.strip().str.lower()\n",
    "GAZ_TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(GAZ_TABLE.GEOID.values).intersection(set(GEO_TABLE.GEOID.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "al\n",
      "GAZ: 1181\n",
      "GEO: 105\n",
      "\n",
      "ak\n",
      "GAZ: 167\n",
      "GEO: 26\n",
      "\n",
      "az\n",
      "GAZ: 1526\n",
      "GEO: 149\n",
      "\n",
      "ar\n",
      "GAZ: 686\n",
      "GEO: 71\n",
      "\n",
      "ca\n",
      "GAZ: 8057\n",
      "GEO: 796\n",
      "\n",
      "co\n",
      "GAZ: 1249\n",
      "GEO: 120\n",
      "\n",
      "ct\n",
      "GAZ: 833\n",
      "GEO: 86\n",
      "\n",
      "de\n",
      "GAZ: 218\n",
      "GEO: 24\n",
      "\n",
      "dc\n",
      "GAZ: 179\n",
      "GEO: 15\n",
      "\n",
      "fl\n",
      "GAZ: 4245\n",
      "GEO: 362\n",
      "\n",
      "ga\n",
      "GAZ: 1969\n",
      "GEO: 193\n",
      "\n",
      "hi\n",
      "GAZ: 351\n",
      "GEO: 29\n",
      "\n",
      "id\n",
      "GAZ: 298\n",
      "GEO: 43\n",
      "\n",
      "il\n",
      "GAZ: 3123\n",
      "GEO: 268\n",
      "\n",
      "in\n",
      "GAZ: 1511\n",
      "GEO: 162\n",
      "\n",
      "ia\n",
      "GAZ: 825\n",
      "GEO: 75\n",
      "\n",
      "ks\n",
      "GAZ: 770\n",
      "GEO: 73\n",
      "\n",
      "ky\n",
      "GAZ: 1115\n",
      "GEO: 81\n",
      "\n",
      "la\n",
      "GAZ: 1148\n",
      "GEO: 101\n",
      "\n",
      "me\n",
      "GAZ: 358\n",
      "GEO: 34\n",
      "\n",
      "md\n",
      "GAZ: 1406\n",
      "GEO: 109\n",
      "\n",
      "ma\n",
      "GAZ: 1478\n",
      "GEO: 135\n",
      "\n",
      "mi\n",
      "GAZ: 2813\n",
      "GEO: 199\n",
      "\n",
      "mn\n",
      "GAZ: 1338\n",
      "GEO: 130\n",
      "\n",
      "ms\n",
      "GAZ: 664\n",
      "GEO: 56\n",
      "\n",
      "mo\n",
      "GAZ: 1393\n",
      "GEO: 130\n",
      "\n",
      "mt\n",
      "GAZ: 271\n",
      "GEO: 39\n",
      "\n",
      "ne\n",
      "GAZ: 532\n",
      "GEO: 42\n",
      "\n",
      "nv\n",
      "GAZ: 687\n",
      "GEO: 50\n",
      "\n",
      "nh\n",
      "GAZ: 295\n",
      "GEO: 39\n",
      "\n",
      "nj\n",
      "GAZ: 2010\n",
      "GEO: 177\n",
      "\n",
      "nm\n",
      "GAZ: 499\n",
      "GEO: 55\n",
      "\n",
      "ny\n",
      "GAZ: 4918\n",
      "GEO: 293\n",
      "\n",
      "nc\n",
      "GAZ: 2195\n",
      "GEO: 212\n",
      "\n",
      "nd\n",
      "GAZ: 205\n",
      "GEO: 30\n",
      "\n",
      "oh\n",
      "GAZ: 2952\n",
      "GEO: 209\n",
      "\n",
      "ok\n",
      "GAZ: 1046\n",
      "GEO: 76\n",
      "\n",
      "or\n",
      "GAZ: 834\n",
      "GEO: 93\n",
      "\n",
      "pa\n",
      "GAZ: 3218\n",
      "GEO: 206\n",
      "\n",
      "ri\n",
      "GAZ: 244\n",
      "GEO: 36\n",
      "\n",
      "sc\n",
      "GAZ: 1103\n",
      "GEO: 106\n",
      "\n",
      "sd\n",
      "GAZ: 222\n",
      "GEO: 29\n",
      "\n",
      "tn\n",
      "GAZ: 1497\n",
      "GEO: 127\n",
      "\n",
      "tx\n",
      "GAZ: 5265\n",
      "GEO: 514\n",
      "\n",
      "ut\n",
      "GAZ: 588\n",
      "GEO: 74\n",
      "\n",
      "vt\n",
      "GAZ: 184\n",
      "GEO: 16\n",
      "\n",
      "va\n",
      "GAZ: 1907\n",
      "GEO: 162\n",
      "\n",
      "wa\n",
      "GAZ: 1458\n",
      "GEO: 166\n",
      "\n",
      "wv\n",
      "GAZ: 484\n",
      "GEO: 41\n",
      "\n",
      "wi\n",
      "GAZ: 1409\n",
      "GEO: 119\n",
      "\n",
      "wy\n",
      "GAZ: 132\n",
      "GEO: 21\n",
      "\n",
      "pr\n",
      "GAZ: 945\n",
      "GEO: 83\n"
     ]
    }
   ],
   "source": [
    "for state in GAZ_TABLE.STUSAB.unique():\n",
    "    print('')\n",
    "    print(state)\n",
    "    print('GAZ: {}'.format(GAZ_TABLE[GAZ_TABLE.STUSAB==state].GEOID.nunique()))\n",
    "    print('GEO: {}'.format(GEO_TABLE[GEO_TABLE.STUSAB==state].GEOID.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>STUSAB</td>\n",
       "      <td>State ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LOGRECNO</td>\n",
       "      <td>Logical Record Number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     column            description\n",
       "0    STUSAB               State ID\n",
       "1  LOGRECNO  Logical Record Number"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESTIMATES_DATA_DICT = SF_DATA_DICT[~SF_DATA_DICT.column.isin(['FILEID', 'FILETYPE', 'CHARITER', 'SEQUENCE'])].reset_index(drop=True)\n",
    "ESTIMATES_DATA_DICT.loc[ESTIMATES_DATA_DICT.column=='STUSAB', 'description'] = 'State ID'\n",
    "ESTIMATES_DATA_DICT.loc[ESTIMATES_DATA_DICT.column=='LOGRECNO', 'description'] = 'Logical Record Number'\n",
    "ESTIMATES_DATA_DICT.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STUSAB</th>\n",
       "      <th>LOGRECNO</th>\n",
       "      <th>B01001_001</th>\n",
       "      <th>B01001_002</th>\n",
       "      <th>B01001_003</th>\n",
       "      <th>B01001_004</th>\n",
       "      <th>B01001_005</th>\n",
       "      <th>B01001_006</th>\n",
       "      <th>B01001_007</th>\n",
       "      <th>B01001_008</th>\n",
       "      <th>...</th>\n",
       "      <th>B99282_005</th>\n",
       "      <th>B99282_006</th>\n",
       "      <th>B99282_007</th>\n",
       "      <th>B99282_008</th>\n",
       "      <th>B99282_009</th>\n",
       "      <th>B99283_001</th>\n",
       "      <th>B99283_002</th>\n",
       "      <th>B99283_003</th>\n",
       "      <th>B99283_004</th>\n",
       "      <th>B99283_005</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ak</td>\n",
       "      <td>1</td>\n",
       "      <td>731545.0</td>\n",
       "      <td>380433.0</td>\n",
       "      <td>24910.0</td>\n",
       "      <td>28292.0</td>\n",
       "      <td>25256.0</td>\n",
       "      <td>14719.0</td>\n",
       "      <td>11147.0</td>\n",
       "      <td>5181.0</td>\n",
       "      <td>...</td>\n",
       "      <td>248183</td>\n",
       "      <td>3838</td>\n",
       "      <td>248361</td>\n",
       "      <td>3849</td>\n",
       "      <td>248350</td>\n",
       "      <td>252199</td>\n",
       "      <td>7194</td>\n",
       "      <td>7194</td>\n",
       "      <td>10098</td>\n",
       "      <td>239283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ak</td>\n",
       "      <td>2</td>\n",
       "      <td>474992.0</td>\n",
       "      <td>240654.0</td>\n",
       "      <td>15669.0</td>\n",
       "      <td>17866.0</td>\n",
       "      <td>15164.0</td>\n",
       "      <td>9242.0</td>\n",
       "      <td>7846.0</td>\n",
       "      <td>3480.0</td>\n",
       "      <td>...</td>\n",
       "      <td>166396</td>\n",
       "      <td>2680</td>\n",
       "      <td>166398</td>\n",
       "      <td>2693</td>\n",
       "      <td>166385</td>\n",
       "      <td>169078</td>\n",
       "      <td>4779</td>\n",
       "      <td>4779</td>\n",
       "      <td>7555</td>\n",
       "      <td>159895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 35529 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  STUSAB  LOGRECNO  B01001_001  B01001_002  B01001_003  B01001_004  \\\n",
       "0     ak         1    731545.0    380433.0     24910.0     28292.0   \n",
       "1     ak         2    474992.0    240654.0     15669.0     17866.0   \n",
       "\n",
       "   B01001_005  B01001_006  B01001_007  B01001_008  ...  B99282_005  \\\n",
       "0     25256.0     14719.0     11147.0      5181.0  ...      248183   \n",
       "1     15164.0      9242.0      7846.0      3480.0  ...      166396   \n",
       "\n",
       "   B99282_006  B99282_007  B99282_008  B99282_009  B99283_001  B99283_002  \\\n",
       "0        3838      248361        3849      248350      252199        7194   \n",
       "1        2680      166398        2693      166385      169078        4779   \n",
       "\n",
       "   B99283_003  B99283_004  B99283_005  \n",
       "0        7194       10098      239283  \n",
       "1        4779        7555      159895  \n",
       "\n",
       "[2 rows x 35529 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESTIMATES.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>STUSAB</td>\n",
       "      <td>State ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>SUMLEVEL</td>\n",
       "      <td>Summary Level</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     column    description\n",
       "0    STUSAB       State ID\n",
       "1  SUMLEVEL  Summary Level"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GEO_DATA_DICT = GEO_DATA_DICT[~GEO_DATA_DICT.column.isin(['FILEID', 'FILETYPE', 'CHARITER', 'SEQUENCE'])].reset_index(drop=True)\n",
    "GEO_DATA_DICT.loc[GEO_DATA_DICT.column=='STUSAB', 'description'] = 'State ID'\n",
    "GEO_DATA_DICT.loc[GEO_DATA_DICT.column=='LOGRECNO', 'description'] = 'Logical Record Number'\n",
    "GEO_DATA_DICT.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STUSAB</th>\n",
       "      <th>LOGRECNO</th>\n",
       "      <th>NECTADIV</th>\n",
       "      <th>BLANK1</th>\n",
       "      <th>CDCURR</th>\n",
       "      <th>PCI</th>\n",
       "      <th>COMPONENT</th>\n",
       "      <th>COUSUB</th>\n",
       "      <th>US</th>\n",
       "      <th>PLACE</th>\n",
       "      <th>...</th>\n",
       "      <th>AIHHTLI</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>BLKGRP</th>\n",
       "      <th>ZCTA5</th>\n",
       "      <th>STATECE</th>\n",
       "      <th>AITSCE</th>\n",
       "      <th>REGION</th>\n",
       "      <th>MEMI</th>\n",
       "      <th>BLANK4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ak</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ak</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  STUSAB  LOGRECNO  NECTADIV  BLANK1  CDCURR  PCI COMPONENT  COUSUB  US  \\\n",
       "0     ak         1       NaN     NaN     NaN  NaN        00     NaN NaN   \n",
       "1     ak         2       NaN     NaN     NaN  NaN        01     NaN NaN   \n",
       "\n",
       "   PLACE  ...  AIHHTLI  STATE  COUNTY  BLKGRP  ZCTA5  STATECE  AITSCE REGION  \\\n",
       "0    NaN  ...      NaN    2.0     NaN     NaN    NaN      NaN     NaN    NaN   \n",
       "1    NaN  ...      NaN    2.0     NaN     NaN    NaN      NaN     NaN    NaN   \n",
       "\n",
       "   MEMI BLANK4  \n",
       "0   NaN    NaN  \n",
       "1   NaN    NaN  \n",
       "\n",
       "[2 rows x 53 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GEO_TABLE.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STUSAB</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>ALAND</th>\n",
       "      <th>AWATER</th>\n",
       "      <th>ALAND_SQMI</th>\n",
       "      <th>AWATER_SQMI</th>\n",
       "      <th>INTPTLAT</th>\n",
       "      <th>INTPTLONG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>al</td>\n",
       "      <td>1001020100</td>\n",
       "      <td>9817813</td>\n",
       "      <td>28435</td>\n",
       "      <td>3.791</td>\n",
       "      <td>0.011</td>\n",
       "      <td>32.481959</td>\n",
       "      <td>-86.491338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>al</td>\n",
       "      <td>1001020200</td>\n",
       "      <td>3325680</td>\n",
       "      <td>5669</td>\n",
       "      <td>1.284</td>\n",
       "      <td>0.002</td>\n",
       "      <td>32.475758</td>\n",
       "      <td>-86.472468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  STUSAB       GEOID    ALAND  AWATER  ALAND_SQMI  AWATER_SQMI   INTPTLAT  \\\n",
       "0     al  1001020100  9817813   28435       3.791        0.011  32.481959   \n",
       "1     al  1001020200  3325680    5669       1.284        0.002  32.475758   \n",
       "\n",
       "   INTPTLONG                                                                                                                               \n",
       "0                                         -86.491338                                                                                       \n",
       "1                                         -86.472468                                                                                       "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAZ_TABLE.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cen_20191_estimates_dd table\n",
      "Writing cen_20191_estimates table\n",
      "Writing cen_20191_geo_dd table\n",
      "Writing cen_20191_geo table\n",
      "Writing cen_20191_gaz table\n"
     ]
    }
   ],
   "source": [
    "OUTPUTS = {\n",
    "    'cen_20191_estimates_dd': ESTIMATES_DATA_DICT,\n",
    "    'cen_20191_estimates': ESTIMATES,\n",
    "    'cen_20191_geo_dd': GEO_DATA_DICT,\n",
    "    'cen_20191_geo': GEO_TABLE,\n",
    "    'cen_20191_gaz': GAZ_TABLE,\n",
    "}\n",
    "\n",
    "for f, df in OUTPUTS.items():\n",
    "    print('Writing {} table'.format(f))\n",
    "    #df.to_csv(os.path.join(RES_DIR, '{}.csv'.format(f)), index=None)\n",
    "    df.to_pickle(os.path.join(RES_DIR, '{}.pkl'.format(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
